{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d70b098",
   "metadata": {},
   "source": [
    "# Information retrieval - Project 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fd93f",
   "metadata": {},
   "source": [
    "# <font color=green>Part1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c52f7",
   "metadata": {},
   "source": [
    "## Cleaning Questions\n",
    "\n",
    "### Function to remove:\n",
    "- Stop words\n",
    "- Punctuatuions\n",
    "- Digits\n",
    "- Removing strings like  __''__ and __``__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47918963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, nltk, re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91903f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "punc = string.punctuation\n",
    "\n",
    "\n",
    "def myCleaner(list):\n",
    "\n",
    "    clean_text = []\n",
    "    for word in list:\n",
    "        word = word.lower()\n",
    "        if word not in (english_stopwords) and (word not in punc):\n",
    "            word = re.sub('[0-9]+','',word).strip()\n",
    "            word = re.sub(\"[``|'']+\",'',word).strip()            \n",
    "\n",
    "            if len(word) > 0:\n",
    "                clean_text.append(word)        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd5359",
   "metadata": {},
   "source": [
    "## STEM\n",
    "- Function to do stemming process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e964d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ca095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myStemmer(list):\n",
    "    stemmed_list = []\n",
    "    for word in list:\n",
    "        stemmed_list.append(stemmer.stem(word))\n",
    "    return stemmed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe4c6f",
   "metadata": {},
   "source": [
    "## preprocess\n",
    "\n",
    "- Function to preprocess dataset Using __myCleaner__ and __myStemmer__ and __Regular expression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10398424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7098e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file):\n",
    "    coarse = list()\n",
    "    fine = list()\n",
    "    preprocessed = list()\n",
    "    with open(file) as fh:\n",
    "        for line in fh:\n",
    "            question = re.findall('.+:[\\S]+ (.+)',line)[0]\n",
    "            \n",
    "            question = question.split() #Convert each question into List\n",
    "            stop = myCleaner(question)\n",
    "            stem = myStemmer(stop)\n",
    "            \n",
    "            \n",
    "            if len(stem) == 0:\n",
    "                continue\n",
    "            \n",
    "            CleanedQuestion = ' '.join(stem)\n",
    "            \n",
    "            if CleanedQuestion in preprocessed: #Skip duplicate questions\n",
    "                continue\n",
    "            \n",
    "            coarse.append(re.findall('([\\S]+):',line)[0])\n",
    "            fine.append(re.findall('.+:([\\S]+) ',line)[0])\n",
    "            preprocessed.append(CleanedQuestion)\n",
    "\n",
    "    return preprocessed, coarse, fine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4d562",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "- Function to assign each class a number  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31dcde",
   "metadata": {},
   "source": [
    "#### *Function to get list of classes used in dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b908b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fine_dict():\n",
    "    fine = {}\n",
    "    j = 0\n",
    "    with open('train_5500.label.txt') as fh:\n",
    "        for line in fh:\n",
    "            c = re.findall('.+:([\\S]+) ',line)[0] \n",
    "            if c not in fine:\n",
    "                fine[c] = j + 1\n",
    "                j += 1\n",
    "    return fine   \n",
    "\n",
    "def get_coarse_dict():\n",
    "    coarse = {}\n",
    "    i = 0\n",
    "    with open('train_5500.label.txt') as fh:\n",
    "        for line in fh:\n",
    "                c = re.findall('([\\S]+):',line)[0]\n",
    "                if c not in coarse:\n",
    "                        coarse[c] = i + 1\n",
    "                        i += 1\n",
    "    return coarse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbbbf6d",
   "metadata": {},
   "source": [
    "#### *assign number to each class and vice-versa*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c7983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(dictionary):\n",
    "    r = {}\n",
    "    for i,j in dictionary.items():\n",
    "        r[j] = i\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5966d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse = get_coarse_dict()\n",
    "fine = get_fine_dict()\n",
    "\n",
    "rev_coarse = reverse(coarse)\n",
    "rev_fine = reverse(fine)\n",
    "\n",
    "              \n",
    "def encode(list_,coarseORfine):\n",
    "    encList = []\n",
    "    if coarseORfine == 'coarse' :\n",
    "        for item in list_:\n",
    "            encList.append(coarse[item.upper()])\n",
    "        return encList\n",
    "        \n",
    "    elif coarseORfine == 'fine':\n",
    "        for item in list_:\n",
    "            encList.append(fine[item.lower()])\n",
    "        return encList\n",
    "    \n",
    "def decode(list_, coarseORfine):\n",
    "    decList = []\n",
    "    if coarseORfine == 'coarse' :\n",
    "        for item in list_:\n",
    "            decList.append(rev_coarse[item])\n",
    "        return decList\n",
    "        \n",
    "    elif coarseORfine == 'fine':\n",
    "        for item in list_:\n",
    "            decList.append(rev_fine[item])\n",
    "        return decList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900299a",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "- Function to calculate tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd83564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "def vectorize(list,trte):\n",
    "    if trte == 'tr':\n",
    "        count_vector = countvec.fit_transform(list)\n",
    "        tfidf_vector = tfidf.fit_transform(count_vector).toarray()\n",
    "        # print(countvec.get_feature_names_out())\n",
    "        # print(count_vector.toarray())  \n",
    "        return tfidf_vector\n",
    "    \n",
    "    elif trte == 'te':\n",
    "        count_vector = countvec.transform(list)\n",
    "        tfidf_vector = tfidf.transform(count_vector).toarray()\n",
    "        # print(countvec.get_feature_names_out())\n",
    "        # print(count_vector.toarray())\n",
    "        return tfidf_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075a566",
   "metadata": {},
   "source": [
    "## Train\n",
    "- function to make models learn __coarse__ class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e883ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import time\n",
    "from vectorize import vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6601deb",
   "metadata": {},
   "source": [
    "#### *Making data ready for training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26aff2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess('train_5500.label.txt')[0]\n",
    "y_train_coarse = preprocess('train_5500.label.txt')[1]\n",
    "x_train_tfidf = vectorize(x_train,'tr')\n",
    "\n",
    "x_test = preprocess('TREC_10.label.txt')[0]\n",
    "y_test_coarse = preprocess('TREC_10.label.txt')[1]\n",
    "x_test_tfidf = vectorize(x_test,'te')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a1759",
   "metadata": {},
   "source": [
    "#### *Training*\n",
    "- This function after training, saves each model for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2597ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part1():\n",
    "    model_prediction_part1 = dict()\n",
    "    times = dict()\n",
    "    \n",
    "    # Multinomial Naive Bayes\n",
    "    s11 = time.time() \n",
    "    model = MultinomialNB().fit(x_train_tfidf, encode(y_train_coarse,'coarse'))\n",
    "    e11 = time.time()\n",
    "    filename = 'Multinomial.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    s12 = time.time()\n",
    "    model_prediction_part1['Multinomial'] = model.predict(x_test_tfidf)\n",
    "    e12 = time.time()\n",
    "    times['Multinomial'] = ((e11-s11) * 10**3,(e12-s12) * 10**3)\n",
    "\n",
    "    # Bernoulli Naive Bayes\n",
    "    s21 = time.time()\n",
    "    model = BernoulliNB().fit(x_train_tfidf, encode(y_train_coarse,'coarse'))\n",
    "    e21 = time.time()\n",
    "    filename = 'Bernoulli_Naive_Bayes.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    s22 = time.time()\n",
    "    model_prediction_part1['Bernoulli'] = model.predict(x_test_tfidf) \n",
    "    e22 = time.time()\n",
    "    times['Bernoulli'] = ((e21-s21) * 10**3,(e22-s22) * 10**3)\n",
    "\n",
    "\n",
    "    # SVM - Linear Kernel\n",
    "    s31 = time.time()\n",
    "    model = SVC(kernel='linear').fit(x_train_tfidf, encode(y_train_coarse,'coarse'))\n",
    "    e31 = time.time()\n",
    "    filename = 'SVM_LinearKernel.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    s32 = time.time()\n",
    "    model_prediction_part1['SVM|Linear Kernel'] = model.predict(x_test_tfidf)\n",
    "    e32 = time.time()\n",
    "    times['SVM|Linear Kernel'] = ((e31-s31) * 10**3,(e32-s32) * 10**3)\n",
    "\n",
    "    # SVM - rbf\n",
    "    s41 = time.time()\n",
    "    model = SVC().fit(x_train_tfidf, encode(y_train_coarse,'coarse'))\n",
    "    e41 = time.time()\n",
    "    filename = 'SVM_rbf.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    s42 = time.time()\n",
    "    model_prediction_part1['SVM|rbf'] = model.predict(x_test_tfidf)\n",
    "    e42 = time.time()\n",
    "    times['SVM|rbf'] = ((e41-s41) * 10**3,(e42-s42) * 10**3)\n",
    "\n",
    "    #KNN\n",
    "    Ks = [3,5,6]\n",
    "    for k in Ks:\n",
    "        s51 = time.time()\n",
    "        model = KNeighborsClassifier(n_neighbors = k).fit(x_train_tfidf, encode(y_train_coarse,'coarse'))\n",
    "        e51 = time.time()\n",
    "        filename = f'knn{k}.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        s52 = time.time()\n",
    "        model_prediction_part1[f'knn|k={k}'] = model.predict(x_test_tfidf)\n",
    "        e52 = time.time()\n",
    "        times[f'knn|k={k}'] = ((e51-s51) * 10**3,(e52-s52) * 10**3)\n",
    "        \n",
    "    print(\"\\n                accuracy\")\n",
    "    for model_name in model_prediction_part1.keys():\n",
    "        print(f\"{model_name} :{' '*(25 - len(model_name))}\",round(accuracy_score(encode(y_test_coarse,'coarse'), model_prediction_part1[model_name])*100, 2))\n",
    "        # print(model_name, ': ', round(accuracy_score(encode(y_test_coarse,'coarse'), model_prediction_part1[model_name])*100, 2))\n",
    "\n",
    "\n",
    "    print(f\"\\n\\n{'.'*66}\")\n",
    "    for model_name in model_prediction_part1.keys():\n",
    "        macro = precision_recall_fscore_support(encode(y_test_coarse,'coarse'),model_prediction_part1[model_name],average='macro',zero_division=0)\n",
    "        micro = precision_recall_fscore_support(encode(y_test_coarse,'coarse'),model_prediction_part1[model_name],average='micro',zero_division=0)\n",
    "\n",
    "        print(f\"\\n{model_name}|{' '*(25 - len(model_name))}   precision         recall          Fscore\")\n",
    "        print('   Macro:                     ',round(macro[0]*100,2), end= '             ')\n",
    "        print(round(macro[1]*100,2), end= '           ')\n",
    "        print(round(macro[2]*100,2))\n",
    "        print('   Micro:                     ',round(micro[0]*100,2), end= '              ')\n",
    "        print(round(micro[1]*100,2),end= '            ')\n",
    "        print(round(micro[2]*100,2)) \n",
    "\n",
    "\n",
    "    print(f\"\\n\\n{'.'*66}\")\n",
    "    print(\"\\nRun time(train,test)[ms]\\n\")\n",
    "    for t in times.items():\n",
    "        print(t[0],end=f\"|{' '*(25 - len(t[0]))}\")\n",
    "        for i in t[1]:\n",
    "            print(round(i,2), end='    ')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de14bc4",
   "metadata": {},
   "source": [
    "#### *Loads models to predict test dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c235723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_part1():\n",
    "    model_prediction_part1 = dict()\n",
    "    times = dict()\n",
    "    # Multinomial Naive Bayes\n",
    "    s11 = time.time() \n",
    "    filename = 'Multinomial.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    e11 = time.time()\n",
    "    s12 = time.time()\n",
    "    model_prediction_part1['Multinomial'] = model.predict(x_test_tfidf)\n",
    "    e12 = time.time()\n",
    "    times['Multinomial'] = ((e11-s11) * 10**3,(e12-s12) * 10**3)\n",
    "\n",
    "    # Bernoulli Naive Bayes\n",
    "    s21 = time.time()\n",
    "    filename = 'Bernoulli_Naive_Bayes.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    e21 = time.time()\n",
    "    s22 = time.time()\n",
    "    model_prediction_part1['Bernoulli'] = model.predict(x_test_tfidf) \n",
    "    e22 = time.time()\n",
    "    times['Bernoulli'] = ((e21-s21) * 10**3,(e22-s22) * 10**3)\n",
    "\n",
    "\n",
    "    # SVM - Linear Kernel\n",
    "    s31 = time.time()\n",
    "    filename = 'SVM_LinearKernel.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    e31 = time.time()\n",
    "    s32 = time.time()\n",
    "    model_prediction_part1['SVM|Linear Kernel'] = model.predict(x_test_tfidf)\n",
    "    e32 = time.time()\n",
    "    times['SVM|Linear Kernel'] = ((e31-s31) * 10**3,(e32-s32) * 10**3)\n",
    "\n",
    "    # SVM - rbf\n",
    "    s41 = time.time()\n",
    "    filename = 'SVM_rbf.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    e41 = time.time()\n",
    "    s42 = time.time()\n",
    "    model_prediction_part1['SVM|rbf'] = model.predict(x_test_tfidf)\n",
    "    e42 = time.time()\n",
    "    times['SVM|rbf'] = ((e41-s41) * 10**3,(e42-s42) * 10**3)\n",
    "\n",
    "    #KNN\n",
    "    Ks = [3,5,6]\n",
    "    for k in Ks:\n",
    "        s51 = time.time()\n",
    "        filename = f'knn{k}.sav'\n",
    "        model = pickle.load(open(filename, 'rb'))\n",
    "        e51 = time.time()\n",
    "        s52 = time.time()\n",
    "        model_prediction_part1[f'knn|k={k}'] = model.predict(x_test_tfidf)\n",
    "        e52 = time.time()\n",
    "        times[f'knn|k={k}'] = ((e51-s51) * 10**3,(e52-s52) * 10**3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n                accuracy\")\n",
    "    for model_name in model_prediction_part1.keys():\n",
    "        print(f\"{model_name} :{' '*(25 - len(model_name))}\",round(accuracy_score(encode(y_test_coarse,'coarse'), model_prediction_part1[model_name])*100, 2))\n",
    "        # print(model_name, ': ', round(accuracy_score(encode(y_test_coarse), model_prediction_part1[model_name])*100, 2))\n",
    "\n",
    "\n",
    "    print(f\"\\n\\n{'.'*66}\")\n",
    "    for model_name in model_prediction_part1.keys():\n",
    "        macro = precision_recall_fscore_support(encode(y_test_coarse,'coarse'),model_prediction_part1[model_name],average='macro',zero_division=0)\n",
    "        micro = precision_recall_fscore_support(encode(y_test_coarse,'coarse'),model_prediction_part1[model_name],average='micro',zero_division=0)\n",
    "\n",
    "        print(f\"\\n{model_name}|{' '*(25 - len(model_name))}   precision         recall          Fscore\")\n",
    "        print('   Macro:                     ',round(macro[0]*100,2), end= '             ')\n",
    "        print(round(macro[1]*100,2), end= '           ')\n",
    "        print(round(macro[2]*100,2))\n",
    "        print('   Micro:                     ',round(micro[0]*100,2), end= '              ')\n",
    "        print(round(micro[1]*100,2),end= '            ')\n",
    "        print(round(micro[2]*100,2)) \n",
    "\n",
    "\n",
    "    print(f\"\\n\\n{'.'*66}\")\n",
    "    print(\"\\nRun time(train,test)[ms]\\n\")\n",
    "    for t in times.items():\n",
    "        print(t[0],end=f\"|{' '*(25 - len(t[0]))}\")\n",
    "        for i in t[1]:\n",
    "            print(round(i,2), end='    ')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_part1()\n",
    "\n",
    "load_train_part1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d0290",
   "metadata": {},
   "source": [
    "# <font color=red>End of Part1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3842f",
   "metadata": {},
   "source": [
    "# <font color=green>Part2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0483d",
   "metadata": {},
   "source": [
    "# <font color=green>2.1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ddb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(list_, target):\n",
    "    j = 0\n",
    "    for i in list_:\n",
    "        if i != target:\n",
    "            list_[j] = 0\n",
    "            j += 1\n",
    "        else:\n",
    "            list_[j] = 1\n",
    "            j += 1\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b72014e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_label(y_true, y_pred, labels):\n",
    "    i = 0\n",
    "    accs = dict()\n",
    "    for label in labels:\n",
    "        copy_y_true = y_true.copy()\n",
    "        copy_y_pred = y_pred.copy()\n",
    "        bin_y_true = sub(copy_y_true, label)\n",
    "        bin_y_pred = sub(copy_y_pred, label)\n",
    "        accs[decode(labels, 'coarse')[i]] = round(accuracy_score(bin_y_true,bin_y_pred),2)\n",
    "        i += 1\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31d9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part2():\n",
    "    \n",
    "    x_test = preprocess('TREC_10.label.txt')[0]\n",
    "    y_test_coarse = preprocess('TREC_10.label.txt')[1]\n",
    "    x_test_tfidf = vectorize(x_test,'te')\n",
    "    \n",
    "    labels = ['abbr', 'desc', 'enty', 'hum', 'num', 'loc']\n",
    "    elabels = encode(labels,'coarse')\n",
    "    filename = 'SVM_LinearKernel.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    y_pred = model.predict(x_test_tfidf)\n",
    "    \n",
    "    acc = accuracy_per_label(encode(y_test_coarse,'coarse'), y_pred, encode(labels,'coarse'))\n",
    "    print('ACCURACY')\n",
    "    for i in acc:\n",
    "        print(f\"\\n{i}|{' '*(10 - len(i))}\", acc[i] * 100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"\\n\\n{'.'*66}\")\n",
    "    \n",
    "    metrics = precision_recall_fscore_support(encode(y_test_coarse,'coarse'), y_pred, average=None, labels=elabels)\n",
    "    i = 0\n",
    "    for label in labels:\n",
    "        print(f\"\\n{label}|{' '*(25 - len(label))}   precision         recall\")\n",
    "        print('                              ',round(metrics[0][i],2) * 100, end= '             ')\n",
    "        print(round(metrics[1][i],2)*100)\n",
    "        i += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_part2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119b185",
   "metadata": {},
   "source": [
    "# <font color=green>2.2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_fine = preprocess('train_5500.label.txt')[2]\n",
    "# model = SVC(kernel='linear').fit(x_train_tfidf, encode(y_train_fine,'fine'))\n",
    "\n",
    "# filename = 'SVM_LinearKernel_fine.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74b43327",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tfidf = vectorize(x_test,'te')\n",
    "filename = 'SVM_LinearKernel.sav'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "coarse_pred= model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52521a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "desc=[]\n",
    "enty=[]\n",
    "abbr=[]\n",
    "hum=[]\n",
    "num=[]\n",
    "loc=[]\n",
    "for label in coarse_pred:\n",
    "    if label == 1:\n",
    "        desc.append(x_test[x])\n",
    "        x += 1\n",
    "        continue\n",
    "    if label == 2:\n",
    "        enty.append(x_test[x])\n",
    "        x += 1\n",
    "        continue\n",
    "    if label == 3:\n",
    "        abbr.append(x_test[x])\n",
    "        x += 1\n",
    "        continue\n",
    "    if label == 4:\n",
    "        hum.append(x_test[x])\n",
    "        x += 1\n",
    "        continue\n",
    "    if label == 5:\n",
    "        desc.append(x_test[x])\n",
    "        x += 1\n",
    "        continue\n",
    "    if label == 6:\n",
    "        loc.append(x_test[x])\n",
    "        x += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d5513e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "class_dataset = [desc,enty,abbr,hum,num,loc]\n",
    "filename = 'SVM_LinearKernel_fine.sav'\n",
    "fine_model = pickle.load(open(filename, 'rb'))\n",
    "result = dict()\n",
    "# ['desc','enty','abbr',\"hum\",'num','loc']\n",
    "p = 1\n",
    "for data in class_dataset:\n",
    "    if len(data) == 0:\n",
    "        print(p)\n",
    "        p +=1\n",
    "        continue\n",
    "    data = vectorize(data,'te')\n",
    "    result[p] = fine_model.predict(data)\n",
    "    p += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49766f",
   "metadata": {},
   "source": [
    "# <font color=green>Part3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess('train_5500.label.txt')[0]\n",
    "y_train_coarse = preprocess('train_5500.label.txt')[1]\n",
    "y_train_fine = preprocess('train_5500.label.txt')[2]\n",
    "\n",
    "location = list()\n",
    "y_loc = list()\n",
    "for i in range(len(y_train_coarse)):\n",
    "    if y_train_coarse[i] == 'LOC':\n",
    "        location.append(x_train[i])\n",
    "        y_loc.append(fine[y_train_fine[i]])\n",
    "location_tfidf = vectorize(location,'tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [3, 4, 5, 6, 7]\n",
    "k_preds = dict()\n",
    "for k in ks:\n",
    "    kmeans = KMeans(n_clusters=k,n_init=\"auto\", init='k-means++').fit(location_tfidf)\n",
    "    k_preds[k] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette = dict()\n",
    "for k in ks:\n",
    "    silhouette[k] = silhouette_score(location_tfidf,k_preds[k])\n",
    "\n",
    "randindex = dict()\n",
    "for k in ks:\n",
    "    randindex[k] = rand_score(y_loc,k_preds[k])\n",
    "    \n",
    "#precesion and recal\n",
    "pr = dict()\n",
    "for k in ks:\n",
    "    pr[k] =  precision_recall_fscore_support(y_loc, k_preds[k], zero_division = 1,average = 'macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923569bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"   Silhouette    Rand Index    precision     recall\")\n",
    "for k in ks:\n",
    "    print(f\"{k} |    {round(silhouette[k],4)}         {round(randindex[k],3)}          {round(pr[k][0],2)*100}         {round(pr[k][1],2)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de27fb",
   "metadata": {},
   "source": [
    "# <font color=red>End of Part3</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
